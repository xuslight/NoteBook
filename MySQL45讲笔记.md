## 01｜基础架构 一条 SQL 语句是如何执行的

### MySQL 架构

<img src="/Users/xus7/Documents/微信图片/WX20210918-152243@2x.png" alt="WX20210918-152243@2x" style="zoom:50%;" />

MySQL 分为 Server 层和存储引擎层；

Server 层分为连接器、查询缓存、分析器、优化器、执行器等，跨引擎的服务都在此实现；

存储引擎层负责数据的存储和提取，架构是插件式的，不同的数据存取方式有所不同；

### Server 层的不同部分

#### 连接器

连接器负责建立连接、获取权限、维持和管理连接，连接命令一般如下：

```shell
mysql -h$ip -P$port -u$user -p
```

连接采用的是经典的 TCP 握手；

若用户名和密码认证通过；

* 连接器会到权限表内查找权限，并且该连接的操作都使用此权限；
* 后续如果修改了权限，在当前连接使用的还是读到的那个权限；

客户端没有动静，服务端经过 wait_timeout 就会断开其连接；

数据库中，长连接是指连接成功后，后续请求使用同一个连接；短连接则是执行少量请求就断开、后续重连；

如何解决长连接过多导致的内存占用过高？

* 定期断开长连接，使用一段时间或做了内存占用大的查询，即断开连接；
* 5.7 及以上版本，执行 mysql_reset_connection 重新初始化连接资源；

#### 查询缓存

进行查询时，首先会查看查询缓存；

查询缓存以 key-value 的形式存储着查询语句和查询结果，如果命中则查询效率比较高；

不建议使用，因为**弊大于利**：

* 查询缓存失效频繁，如果有更新数据，那么该表的查询缓存都要删除，除非更新频率很低；
* 将参数 query_cache_type 设置成 DEMAND 即可不开启；
* 需要时加入 SQL_CACHE 显式指定；

```mysql
SELECT SQL_CACHE * FROM T WHERE ID = 10;
```

在 MySQL 8.0 中，查询缓存被完全删除了，因为真的没有太大的用处；

#### 分析器

MySQL 通过分析器了解执行语句需要做什么；

词法分析：识别关键字、表名、列名等；

语法分析：根据语法规则来判断 SQL 语句的语法是否正确；

#### 优化器

执行之前，需要对 SQL 语句进行优化；

比如对索引的选择，或是关联表的连接顺序，在不变更逻辑的基础上，提高语句执行的效率；

#### 执行器

执行器负责执行语句，比如：

```mysql
select * from T where ID=10;
```

1. 首先会对是否能够进行查询有一个权限判断；
2. 有权限就会打开表，并根据表的引擎定义，使用引擎提供的接口；
3. 比如以上的例子：
	1. 调用 InnoDB 引擎接口读取表的第一行，判断 ID 是不是 10，如果是就将其存在结果集中；
	2. 调用引擎接口读取下一行，直到最后一行；
	3. 执行器将结果集返回给客户端；

数据库慢查询日志中有字段 rows_examined，表示执行过程中扫描了多少行，就是调用接口时累加的；

有些场景下，引擎内部扫描的会比 rows_examined 多，并不完全相同；



## 02｜日志系统 一条 SQL 更新语句是如何执行的

### 更新语句执行流程

与查询相同的，更新语句也会走那一套 Server 层和存储引擎层的逻辑；

但更新流程会涉及到不同的日志模块，包括 redo log（重做日志）和 binlog（归档日志）；

为什么要用两种日志做崩溃恢复：https://www.zhihu.com/question/463438061

### 日志模块

#### redo log 重做日志

MySQL 中 WAL 技术，全称是 Write-Ahead-Logging，即先写日志、再写磁盘；

* 在更新时，先将其记录到 redo log 中，并更新内存，此时更新就算完成了；
* 在适当空闲时，将操作更新到磁盘中；

MySQL 中的 redo log 缓冲是固定大小的，循环利用，因此需要在满的时候刷到磁盘中；

redo log 使数据库拥有 crash-safe 的能力，保证数据库异常重启之后，还能够恢复到原样；

redo log 是存储引擎上的，是基于数据页的；

#### binlog 归档日志

redo log 是 InnoDB 独有的日志，而 binlog 是属于 Server 层的日志，也就是说不管使用何种引擎都可以用；

##### 同 redo log 的不同

1. redo log 是 InnoDB 引入独有的，而 binlog 是 Server 层通用的归档日志；
2. redo log 是物理日志，记录在某个数据页上做了什么修改，而 binlog 是逻辑日志，记录的是语句的逻辑，比如给 c 加 1 之类的；
3. redo log 是循环写的，不能写了会先刷盘再写入，而 binlog 是追加写的，不断往上增加语句；

##### 执行语句时的流程

以以下语句为例：

```mysql
update T set c=c+1 where ID=2;
```

1. 执行器调引擎接口来获取 ID=2 的行，引擎用树搜索；
2. 如果本身在内存中就直接返回给执行器，否则从磁盘中读入内存，再返回给执行器；
3. 执行器拿到数据后，更新数据，并再调用引擎接口来进行更新数据；
4. 引擎将其更新到内存中，同时更新到 redo log 中，redo log 处于 prepare 状态，并返回执行器可以提交；
5. 执行器记录 binlog，并将其写入磁盘；
6. 执行器调用引擎的提交事务接口，刚写入的 redo log 改成 commit 状态，更新完成；

#### 两阶段提交

可以看到，redo log 进行了两阶段提交，才最终存入到磁盘中；

##### 为什么要用两阶段提交

为了保证两份日志的一致性；

1. redo log 实际上记录的是数据库本身的状态，而 binlog 则是我们对数据库做的操作；
2. 因此，在数据恢复的时候，如果要恢复原来数据库的状态，其实是要恢复成 redo log 记录的状态的；
3. 但 redo log 是循环写并且刷盘的，我们业务上使用 binlog 来进行恢复；
4. 因此 binlog 需要和 redo log 保持一致，才能让恢复出来的数据和原来数据库的状态保持一致；

##### 不用两阶段提交发生 crash 会不一致

先写 redo log 再写 binlog，binlog 恢复比 redolog 记录的原数据库状态少一条；

先写 binlog 再写 redo log，binlog 恢复比 redolog 记录的原数据库状态多一条；

##### 实际场景如何做恢复

通过**全量备份+应用 binlog** 来进行备库或数据恢复；

#### 小结

1. redo log 用于保证 crash-safe 的能力，因为数据变更从内存刷到磁盘是延时的，因此需要 redo log 来保证；
2. innodb_flush_log_at_trx_commit 参数设置为 1，每次 redo log 都会存储到磁盘；
3. sync_binlog 参数设置为 1，表示每次事务 binlog 都会持久化到磁盘；

### 问题

一周一备好还是一天一备好？

RTO 目标恢复时间，一天一备自然是最长的恢复时间最短；

但是备份的频率高，需要更多的存储空间和计算资源，需要根据业务情况来进行权衡；



## 03｜事务隔离：为什么你改了我还是看不见？

### 前言

MySQL 的事务隔离是在引擎层面实现的；

有的引擎不支持事务，比如 MyISAM，因此他就被几乎淘汰了；

### 隔离性与隔离级别

可能出现的脏读、不可重复读、幻读问题；

隔离越强，执行效率就会越低；

隔离级别，读未提交、读提交、可重复读、串形化：

* 读未提交，能够读到事务没有提交的更改数据；
* 读提交，事务提交后，其他事务就能够读到数据的更改；
* 可重复度，同一事务哪前后同样读取的结果相同；
* 串形化，冲突时必须串形化执行；

事实上，数据库理会创建视图，访问的时候以视图的逻辑结果为准：

* 可重复度，视图在事务启动时创建，整个事务都是基于此视图的数据开展的；
* 读提交，视图在每个 SQL 语句执行开始创建；
* 读未提交，没有视图概念，直接返回查询的最新值；
* 串形化，通过锁来避免并行访问，不涉及到视图；

配置隔离级别，启动参数 transaction-isolation 设置为 READ-COMMITED 之类的；

### 事务隔离的实现

以可重复读为例；

MySQL 中，每条记录在更新的时候都会同时记录回滚操作，记录上的值通过回滚可以回到前一值；

<img src="/Users/xus7/Documents/微信图片/WX20210919-164851@2x.png" alt="WX20210919-164851@2x" style="zoom:50%;" />

不同时刻启动的事务有不同的 read-view，就是事务的多版本并发控制；

MVCC 多版本并发控制：https://www.jianshu.com/p/8845ddca3b23；

当没有事务再需要用到这些回滚日志的时候，回滚日志就会被删除，即没有比这个日志更早的 read-view 的时候；

长事务意味着系统里面会存在很老的事务视图，导致占用大量的存储空间；

### 事务的启动方式

MySQL 事务启动的方式：

1. 显式启动，使用 begin 或 strat transaction，配套语句是 commit 和 rollback；
2. set autocommit=0，会将线程的自动提交关闭，但自动提交是开启的，需要主动执行 commit rollback 或断开连接；

如果客户端框架连接成功后自动执行 set autocommit=0，且不手动关闭，就会导致长连接意外的长事务；

建议使用 set autocommit=1，通过显式的方式开启和关闭；

如果非要减少语句的交互，使用 commit work and chain 语法，即提交事务后自动启动下一事务；



## 03.1｜MVCC 多版本并发控制

* 前提概要
	* 什么是 MVCC；
	* 什么是当前读和快照读；
	* 当前读、快照读和 MVCC 的关系；
* MVCC 实现原理
	* 隐式字段；
	* undo 日志；
	* Read View 读视图；
	* 整体流程；
* MVCC 相关问题
	* RR 如何在 RC 的基础上解决不可重复读；
	* RC、RR 在 InnoDB 下快照读有什么不同；

### 前提概要

#### 什么是 MVCC

Multi-Version Concurrency Control，实现并发控制的方法之一，实现对数据库的并发访问；

MVCC 在 InnoDB 中解决读-写冲突，能够做非阻塞的并发读，提高并发读性能；

#### 什么是当前读和快照读

##### 当前读

读取记录的最新版本，读取的时候不允许并发事务对数据进行修改，会加锁；

如 select lock in share mode（意向共享锁）、select for update、update、delete 等锁都是当前读；

##### 快照读

不加锁的就是快照读，通过 MVCC 来实现；

MVCC 可以视为行锁的变种，但是在大多数情况下都能够进行非阻塞读；

快照读的前提的隔离级别不是串形化；

#### 当前读、快照读和 MVCC 的关系

MVCC 就是解决读-写冲突，其中读就是快照读，当前读是加锁实现的，属于悲观锁；

MVCC 是维持数据的多个版本，使得读写操作没有冲突；

MVCC 通过 3 个隐式字段、undo 日志和 Read View 来实现的；

#### MVCC 能解决什么问题

##### 数据库并发的三种场景

* 读-读场景，不需要加锁，不竞争；
* 读-写场景，有事务隔离性问题，出现脏读、幻读、不可重复读等；
* 写-写场景，存在更新丢失的情况；

##### MVCC 解决的问题

读-写场景可能的事务隔离性问题，为事务分配单向生长的时间戳，为每个修改保存版本，在读操作之前进行版本的判断，只读事务开始时的快照；

可以解决如下问题：

* 并发读写时读操作不阻塞写操作，写操作也不阻塞读操作；
* 解决事务隔离性问题，如脏读、不可重复读和幻读；

### MVCC 实现原理

依赖三个隐式字段、undo 日志以及 Read View 的读视图；

#### 隐式字段

* DB_TRX_ID：6byte 最近修改记录的事务 ID；
* DB_ROLL_PTR：7byte 回滚指针，指向该记录的上一版本；
* DB_ROW_ID：6byte 若表无主键，会生成一个聚簇索引；
* 另外还有个删除 flag，用于异步删除；

#### undo 日志

数据库的 undo 日志分为两种；

* insert undo 日志：
	* 事务在 insert 时产生的 undo log，事务回滚时需要，在事务提交后可以立即删除；
* update undo 日志：
	* 事务在 update、delete 时产生的 undo log，事务回滚需要、快照读也需要；
	* 只有在快照读或事务回滚不涉及时，才由 purge 线程统一进行删除；

##### purge 线程

purge 做异步删除的工作，进行更新或删除都是设置一下删除位，等到不涉及就会安全删除；

pruge 维护了 read view，最老的活跃事务的 read view，这样 DB_TRX_ID 如果相对于这个读视图可见，就说明可以安全删除；

##### undo log 链

update undo log 实际上是修改的记录链：

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210923190547437.png" alt="image-20210923190547437" style="zoom: 33%;" />

1. 有个事务插入了新数据，隐式主键为 1，事务 ID 和回滚指针为 null；
2. 事务 1 对 name 进行修改；
	1. 修改时，数据库首先会加行排他锁；
	2. 将行数据拷贝到 undo log 中，作为旧记录；
	3. 拷贝完成，将事务 ID 更改为 1，且设置行指针；
	4. 事务完成，释放排他锁；
3. 事务 2 对 age 进行修改；
	1. 修改时，同样增加行排他锁；
	2. 将行数据拷贝到 undo log 中，且加入到 log 链的链头，说明比之前的记录要晚；
	3. 拷贝完成，将事务 ID 更改为 2，且设置行指针；
	4. 事务完成，释放排他锁；

可以看到，其实不同事务的修改，会形成多版本的链表，并通过链表上的位置标识先后顺序；

#### Read View 读视图

##### 什么是 Read View

事务执行快照读时刻产生的读视图，在事务执行快照读的那一刻对于数据库系统的快照，记录并维护系统当前活跃事务的 ID；

事务执行快照读时，通过 Read View 来判断是否能够读取到最新数据，或是 undo log 中的某版本的数据；

##### Read View 的可见性算法

将 Read View 包含的属性理解成三个全局属性：

* trx_list（名字随便取的）：维护 Read View 生成时活跃的事务 ID 列表；
* up_limit_id：trx_list 中最小的事务 ID；
* low_limit_id：Read View 生成时，系统中最大的事务 ID + 1；

事务 ID 执行快照读时遇到某一版本 log 的判断方法：

1. 若 DB_TRX_ID < up_limit_id，说明该事务能够看到该行的修改数据，如果是 >= 则进入下一判断；
2. 若 DB_TRX_ID >= low_limit_id，说明该事务部能够看到该行的数据，否则进入下一判断；
3. 若 DB_YRX_ID 在 Read View 活跃事务列表中，说明还没有 commit 不能看到数据，不在则说明可以看到；
4. 如果判断是不可以看到，那么就需要查看日志链的下一个修改记录了；

### 整体流程

![image-20210923192714761](/Users/xus7/Library/Application Support/typora-user-images/image-20210923192714761.png)

1. 事务 2 对整体数据进行了快照读，假设生成 Read View 时事务 1 和 3 还在活跃，而事务 4 已经提交了；
2. 那么 Read View 的 trx_list 为 1 和 3，up_limit_id 是 1，low_limit_id 是 5；
3. 只有事务 4 进行过修改，因此 undo 链如图；

![image-20210923192943295](/Users/xus7/Library/Application Support/typora-user-images/image-20210923192943295.png)

4. 要看 DB_TRX_ID 为 4 的修改是够可以在该 Read View 可见，4 比 up_limit_id 大，4 又比 low_limit_id 小，而且 4 不在 trx_list 中，说明事务 ID 为 4 的事务的提交是在 Read View 之前的，结果可见；

正是因为生成 Read View 的时机不同，RR 和 RC 才会有不同的快照读结果；

### MVCC 的相关问题

#### RR 是如何在 RC 的基础上解决不可重复读的

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210923193535390.png" alt="image-20210923193535390" style="zoom:50%;" />

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210923193557531.png" alt="image-20210923193557531" style="zoom:50%;" />

两个表中的区别就在于，事务 B 快照读的时机；

表一是在开启事务后进行了快照读，此时事务 A 还没有提交更新，而表二是在 A 更新提交后进行快照读的；

事务中快照读的结果是非常依赖该事务首次出现快照读的地方；

即某个事务中首次出现快照读的地方非常关键，它有决定该事务后续快照读结果的能力；

#### RC、RR 级别下 InnoDB 快照读有什么不同

即生成 Read View 的时机不同；

RR 级别下，对某条记录第一次快照读会创建快照和 Read View，之后对该条记录的快照读都使用该读视图；

RC 级别下，对某条记录的快照读都会创建新的 Read View，因此可以在事务中看到别的事务的提交。



## 04｜深入浅出索引（上）

索引的出现其实就是为了提高查询效率，就和目录一样；

### 索引的常见模型

提高读写效率的数据结构，常见的包括哈希表、有序数组和搜索树；

#### 哈希表

通过哈希函数获取 Key 并对应到相应的 Value，产生冲突的可以使用拉链法来解决；

哈希索引的区间查找显然是非常慢的；

哈希索引适合等值查找的场景，模糊查找也不行，比如 Memcached 以及其他 NoSQL 引擎；

#### 有序数组

在等值查询和范围查询都比较出色；

按照索引列进行排序即可；

若要进行数据的插入和删除，明显的就需要消耗大量的时间来做数据的移位；

有序数组适合静态存储引擎，不会再有修改的数据，用有序数组来做索引肯定不错；

#### 搜索树

考虑到索引不但存储在内存中，也要存储在磁盘中，以页的方式来读取，使用多叉搜索树；

InnoDB 整数索引为例，单个节点的关键字可以有 1200 个，较大的叉数意味着较少的 IO 次数；

### InnoDB 的索引模型

索引组织表，表根据主键顺序以索引的方式存放，表的数据都是在主键索引中的；

主键索引里面存放行数据，是聚簇索引；

非主键索引叶节点存放的是主键的值，查找到之后如果要查询其他列还需要进行一次回表查询，有一定消耗；

### 索引维护

B+ 树为了维护索引的有序性，插入新值的时候会进行必要的维护；

插入时如果目标页满了，就需要进行分裂并挪动部分数据过去，就像 B+ 树分裂一样；

页合并是反过来的过程，将两个相邻页进行合并；

#### 自增主键和非自增主键的选择

AUTO_INCREMENT 开启是否自增主键，如果不指定 id 就会自动 +1；

自增主键的插入，就是顺序插入，不会导致页分裂和数据的挪动，相对来说性能要好；

另外，主键会在所有二级索引中出现，自增主键的整型相对来说占用的空间会更小一些；

业务主键的场景：KV 场景，键唯一且只有一个索引；

### 小结

B+ 树能够很好的配合磁盘读写的特性，减少单词查询的磁盘 IO 次数；

#### 上期问题：如何避免长事务对业务的影响

应用开发端来看：

1. 确认是否使用 set autocommit=1，通过 general_log 确认；
	* general_log 就是将到达 Server 的所有语句都记录下来，一般不会开启，因为数量会非常庞大；
2. 确认是否有不必要的只读事务，只读事务可以去掉；
3. 业务连接数据库，SET_MAX_EXECUTION_TIME 控制语句执行的最长时间，避免因为时间太长而出问题；

数据库端来看：

1. 监控 information_schema.innodb_trx 表，存储了事务信息，设置长事务阈值；
2. Percona 的 pt-kill 工具；
3. 业务功能测试阶段，输出所有 general_log，分析日志提前发现问题；
4. 将 innodb_undo_tablespaces 设置为 2，方便大事务后续的回滚？；



## 05｜深入浅出索引（下）

回到主键索引树搜索的过程，称为回表；

### 覆盖索引

如果要查询的值在二级索引树上，就不需要回表了，速度会快很多；

覆盖索引能够减少树的搜索次数，提升查询性能，是常用的性能优化手段；

在市民信息表上，是否有必要建立身份证号和姓名的联合索引；

如果查询频率高的话，其实是可以考虑的，覆盖索引提升查询性能；

#### 最左前缀原则

B+ 树的联合索引，索引项是按照索引定义里面出现的字段顺序排序的；

逻辑需求查到第一个索引列，就顺序查找后面的索引项，直到找到所有满足条件的索引项；

只要满足最左前缀，包括前几列索引、或者是字符串的前几个字符；

建立联合索引的原则，尽可能减少建立索引的个数，以及索引占用的空间；

#### 索引下推

不符合最左前缀的部分，会如何来查找；

索引首列就是模糊查询或范围匹配，会先找到符合首列索引条件的，再遍历去匹配；

在 MySQL 5.6 之前，会一个个回表查询整行数据，再对比字段值；

在 MySQL 5.6，引入索引下推优化，在索引遍历的过程中，对索引中的字段先做判断，过滤掉不满足条件的索引项，减少回表的次数；

#### 小结

在满足语句的需求下，尽可能减少数据库访问的资源是设计原则之一；

##### 上期问题：通过两个 alter 重建索引 k，和重建主键索引是否可行？

为什么要重建索引？索引可能因为删除、页分裂导致数据不紧凑，重建可以保证按顺序插入且存储更加紧凑；

重建索引 k 是可以先丢弃再新建的，主键索引不行，因为本身就存储着整张表的数据，可以使用：

```mysql
alter table T engine=InnoDB;
```



## 06｜全局锁和表锁：给表加个字段怎么这么多阻碍？

数据库锁设计的初衷是处理并发问题；

MySQL 的锁大致可以分为全局锁、表级锁和行锁；

### 全局锁

对整个数据库实例加锁，``Flush tables with read lock``；

全局锁，整个数据库处于只读状态，并且数据更新语句、数据定义语句等；

全局锁的应用场景，全局逻辑备份，不过全库只读确实蛮危险的；

但是不加全局锁会出现不同的备份时逻辑时间不一致的问题；

如何获取一致性视图，即在可重复度的隔离级别下开启一个事务，而且在 MVCC 的支持下数据是可以更新的；

mysqldump 可以绕过 FTWRL 来进行一致性视图的生成，就是靠的事务，只适用于支持事务的引擎；

**全库只读为什么不使用 set global readonly=true 呢？**

* 有些系统中使用 readonly 进行其他逻辑的判断，比如判断是主库还是被库，修改这个影响面更广；
* 异常处理机制上有差异，FTWRL 连接异常断开，MySQL 会自动释放全局锁，但 readonly 不会自动恢复；

### 表级锁

MySQL 中有两种表级别锁，分别是表锁和元数据锁（MDL）；

#### 表锁

表锁可以通过 lock tables ... read/write 获取，并且通过 unlock tables 释放，或是客户端断开后自动释放；

lock tables 既会限制其他线程读写，也会限制本线程读写；

比如``lock tables t1 read, t2 write``，则本线程对 t1 的写也会被限制住；

#### 元数据锁

MDL 在访问一个表时会自动加上，以保证读写的正确性；

MySQL 5.5 引入，当进行增删改查时增加 MDL 读锁，改变表结构时增加 MDL 写锁；

* 读锁之间互不排斥，可以有多个线程同时对一张表进行增删改查；
* 读写锁之间、写锁之间时互斥的，用来保证表结构变更的安全性；

##### 小表加字段导致整个库挂了？

出现问题的操作序列：

1. 开启 A 事务，并读取数据，此时获取 MDL 读锁，在事务结束之后才会释放；
2. B 读取数据，获取 MDL 读锁；
3. C 要增加字段，获取 MDL 写锁时被阻塞；
4. D 读取数据，获取 MDL 读锁时被 C 阻塞；
5. 若后续读取数据频繁，以及重试机制，导致被疯狂阻塞；

如何解决：

1. 解决长事务 A，通过监控 information_schema 库的 innodb_trx，要执行 DDL 的时候，就先暂停 DDL，或者将可能的长事务 Kill 掉；
2. alter table 的加字段内设置等待时间，若无法获取 MDL 写锁就自动放弃，等待后续重试；

```mysql
ALTER TABLE tbl_name NOWAIT ADD COLUMN ...
ALTER TABLE tbl_name WAIT n ADD COLUMN ...
```

### 小结

全局锁一般用于逻辑备份，FTWRL；

表级锁一般用于没有行锁的引擎；

MDL 直到事务提交才会释放，在做表结构变更的时候，必须要注意不要阻塞线上查询；



## 07｜行锁功过：怎么减少行锁对性能的影响

MySQL 的行锁是在引擎层实现的；

InnoDB 的行锁，来减少锁冲突提升业务并发度；

### 两阶段锁

InnoDB 事务中，行锁是在需要时候才加上的，并且在事务结束之后才释放；

因此，如果事务中需要锁多个行，要把最可能造成锁冲突的语句放在最后，减少锁冲突的时间；

### 死锁和死锁检测

并发系统不同线程出现资源的循环依赖，会进入无限等待的状态，称为死锁；

#### 策略

* 等待直到超时，设置 innodb_lock_wait_timeout 参数；
* 死锁检测，主动回滚死锁链条中的某个事务，其他事务得以进行，设置 innodb_deadlock_detect 为 on；

策略一，往往会阻塞很长时间；

策略二，性能较低，每次事务获取锁的时候，都需要查看是否可能会出现问题，热点行会导致 CPU 被占用；

#### 解决热点行的问题

* 关闭死锁检测；
	* 如果能确保一定不出现死锁，就把死锁检测关掉；
	* 但在业务上出现死锁回滚再重试是业务无损的，而等待超时是业务有损的；

* 控制并发度，降低死锁检测的性能消耗；

* 修改 MySQL 源码，直接相同行的更新在进入引擎层之前排队；

* 设计上优化；
	* 将单行改成多行来存储；
	* 进行类似于负载均衡的操作；

### 小结

如果事务中需要获取多个行锁，将可能引发更多冲突的写在后面；

#### 上期问题

当备库用 -single-transaction（MCVV 保证） 做逻辑备份的时候，从主库传来 DDL 的 binlog 会如何；

关于备份的关键语句：

```mysql
Q1:SET SESSION TRANSACTION ISOLATION LEVEL REPEATABLE READ;
Q2:START TRANSACTION WITH CONSISTENT SNAPSHOT；
/* other tables */
Q3:SAVEPOINT sp;
/* 时刻 1 */
Q4:show create table `t1`;
/* 时刻 2 */
Q5:SELECT * FROM `t1`;
/* 时刻 3 */
Q6:ROLLBACK TO SAVEPOINT sp;
/* 时刻 4 */
/* other tables */
```

1. 设置隔离级别为 RR；
2. 用 WITH CONSISTENT SNAPSHOT 得到一致性视图 Q2；
3. 设置保存点 Q3；
4. 拿到表结构 Q4，进行数据备份 Q5，回滚到 sp 并释放 MDL 锁 Q6；

参考答案：

1. 若 DDL 在 Q4 之前到达，则备份拿到的是 DDL 执行后的表结构；
2. 若在时刻 2 到达，表结构被修改，则会出现问题，因为表结构发生了变化；
3. 在时刻 2 和时刻 3 之间到达，mysqldump 占着 MDL 读锁，binlog 被阻塞，主从延迟直到 Q6 执行完成；
4. 时刻 4 开始，mysqldump 释放 MDL 读锁，DDL 与备份无关；



## 08｜事务到底是隔离还是不是隔离的？

事务获取行锁，要更新数据的时候，读取到的是什么值？是要获取当前读，肯定是新值吧？

事务的启动时机并不是 begin/start transaction，而是第一个操作表的语句；

通过 start transaction with consistent snapshot 命令可以直接启动事务；

MySQL 有两个视图的概念：

* view，用于查询语句定义的虚拟表，就和表一样使用在查询当中；
* MVCC 的一致性视图，即 consistent read view，支持 RC 和 RR 的隔离级别的实现；

### 快照如何工作

事务 ID 是唯一且递增的；

每行数据都可能会有多个版本，事务更新数据，都会生成新的数据版本；

事务获取数据时，是只能看到比他之前的版本，当然如果是其本身更新的，那也是可以看到的；

read-view 是开启时活跃的事务 ID 数组、低水位最小事务 ID、高水位最大事务 ID + 1；

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210927110743071.png" alt="image-20210927110743071" style="zoom:50%;" />

对于事务本身 ID 以及数据行记录的事务 ID：

1. 若行 ID 落在绿色部分，可见；
2. 落在红色部分，不可见；
3. 落在黄色部分，如果是集合内的，说明还没提交，不可见；
4. 如果不是集合内的，说明提交了，可见；

因此，创建快照其实只要获取到这些相关的数据就可以了；

### 更新逻辑

更新数据是不根据版本的，不进行快照读；

更新数据先读后写，而且是当前读，也就是读取的是最新的数据并进行修改；

update 是使用当前读，如果 select 增加了共享锁 lock in share mode 或排他锁 for update，也进行当前读；

```mysql
select k from t where id = 1 lock in share mode;
select k from t where id = 1 for update;
```

#### 如果 C 是事务

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210928181722542.png" alt="image-20210928181722542" style="zoom:50%;" />

如果是这样子的，C 是一个事务，而不是一个简单的更新语句（当然内部也算事务）；

C 在进行 update 的时候会加锁，而且这个锁直到事务结束才会释放；

因此 B 会因为获取不到行锁而阻塞，直到行锁被释放，才能继续运行，当然结果也是一样的；

#### 事务可重复读的能力如何实现

可重复读的核心就是一致性读（consistent read）；

事务更新的时候，只能用当前读，当前读是会把目标数据锁定的，事务完成后锁才会释放；

读提交和可重复读的区别：

* 可重复读是在事务开始时，获取到一致性视图，之后事务内的查询都用该视图；
* 读提交是每个语句执行之前都会获取当前的一致性视图；

### 小结

InnoDB 行数据有多个版本，每个数据版本有自己的 row_trx_id，每个事务或语句有自己的一致性视图；

* 可重复读，语句只承认事务开始前就提交的数据；
* 读提交，语句承认在语句之前就提交的数据；

当前读，总是最新版本；

表结构不支持可重复读，因为表结构没有 rox_trx_id 之类的，只能进行当前读；

MySQL 8.0 将表结构放入到引擎中，可能也能够支持表结构的可重复读了；

#### 如何删除表的前 10000 行

比较好的做法是在同一连接中执行 20 次且每次删除 500 行；

直接删除 10000 行会导致锁占用时间太长，而且长事务出现其他的问题；

20 个连接同时删除 500 个，显然是人为的锁冲突，不过如果能够业务上将 ID 分开来，也是可以的；



## 09｜普通索引和唯一索引，应该如何选择？

不同的业务场景下，使用普通索引还是唯一索引；

如果在维护市民系统，且业务上保证不会有相同的 card_id 输入，会考虑增加索引；

那么是创建普通索引还是唯一索引呢？

### 查询过程

```mysql
select id from t where k = 5
```

* 普通索引，在查找到索引叶子结点之后，顺序遍历查找 k != 5 的节点，至少遍历两个节点；
* 唯一索引，在查找到索引叶子后，因为索引的唯一性，就不会再继续查找下去；

性能差距几乎没有...

InnoDB 是按页来进行数据的读写的，所以很可能会将之后的叶子结点也读入到内存中；

因此普通索引的多遍历一个其实也无所谓，一次指针寻找+一次计算；

### 更新过程

更新过程中需要使用到 change buffer；

**change buffer**

更新数据时，如果数据在内存中就直接更新；

如果内存中还没有把数据读入：

* 不影响一致性的情况下，就直接在 change buffer 保存这个更新，不需要从磁盘中来读了；
* 在下次查询要用到数据时，从磁盘读入内存，再将 change buffer 的更新应用上去；

change buffer 是可持久化数据，在内存中有拷贝，也会刷到磁盘上；

change buffer 应用到原数据页叫做 merge；

访问该数据页会 merge，系统后台线程也会定期 merge，另外连接关闭时也会 merge；

change buffer 使用的是 buffer pool，通过 innodb_change_buffer_max_size 来设置百分比；

**什么时候使用 change buffer**

唯一索引：

1. 如果是唯一索引，那么更新时都需要判断是否违背了唯一的要求，会将数据读到内存中；
2. 此时，直接更新内存会快很多，而不需要额外再更新 change buffer；

普通索引，是可以使用的，也只有普通索引需要使用 change buffer；

**插入新记录的流程**

如果要更新的目标页在内存中：

* 唯一索引，找到位置，判断冲突，插入，结束；
* 普通索引，找到位置，插入，结束；

如果要更新的目标页不在内存中：

* 唯一索引，需要将数据页读入内存来判断是否冲突，插入，结束；
* 普通索引，将记录更新在 change buffer 即可；

将数据从磁盘读入内存涉及到磁盘的随机 IO 访问，是数据库中成本最高的操作之一；

change buffer 减少了磁盘的随机访问，能够较好地提高性能；

### change buffer 的使用场景

普通索引的场景，使用 change buffer 一定能够提高性能吗？

对于写多读少的业务，页面在写完之后被访问到的概率比较小，此时使用 change buffer 效果比较好，常见如账单类、日志类的业务；

如果是读多写少，更新之后马上被查询，即使被记录在 change buffer，也会马上访问数据页进行 merge，等于是多做了一道工序，反而会增加消耗；

### 索引的选择和实战

查询能力上面没有什么差别，主要是在更新性能上；

尽量使用普通索引；

如果是更新之后，马上伴随着查询，那么最好关闭 change buffer；

其他情况下，change buffer 都基本能够提升性能，配合使用对于数据量大的表的更新优化是比较明显的；

特别是使用的是机械硬盘时；

### change buffer 和 redo log

```mysql
insert into t(id, k) values (id1, k1), (id2, k2);
```

**假设 k1 的数据页已在内存中，而 k2 的数据页没有在内存中：**

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210929104933388.png" alt="image-20210929104933388" style="zoom:50%;" />

涉及了四个部分，内存、redo log、数据表空间和内存表空间；

* k1 的记录直接在内存中进行改变；
* k2 的记录会写在 change buffer 中，且保存 change buffer 进入到磁盘；
* redo log 则是记录实际的变化，包括 k1 的变化和 k2 更新时 change buffer 的变化；

只进行了两次内存操作和一次磁盘操作（顺序写，redo log）；

另外的 change buffer 写磁盘和 k1 更新都是异步的；

**之后的读请求需要如何处理：**

```mysql
select * from t where k in (k1, k2);
```

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20210929133228525.png" alt="image-20210929133228525" style="zoom:50%;" />

* 对于 k1，本身就在内存中，直接读即可；
* 对于 k2，本身不在内存中，需要随机读磁盘到内存，并且通过 change buffer 进行修改，读取；

因此，redo log 主要是节省随机写磁盘 IO 消耗（改为顺序写），而 change buffer 是节省随机读磁盘 IO 消耗；

### 小结

由于唯一索引没有办法使用到 change buffer 来优化性能，因此建议使用普通索引；

#### 是否使用唯一索引？

1. 业务的正确性优先，如果业务不能保证，或业务需要数据库来做唯一约束，那么只能使用唯一索引；
2. “归档库”场景可以使用唯一索引，归档数据没有唯一性冲突就可以，当然和普通索引其实类似；

#### 上期问题

数据无法修改的情况，主要是考虑到更新数据使用的是当前读，每次都会使用到最新数据；



## 10｜MySQL 为什么有时候会选错索引？

使用哪个索引是由 MySQL 来确定的；

可能会出现，本来可以执行得很快的语句，由于 MySQL 选错索引而导致执行速度变慢；

问题的场景复现就不在这里展开的，具体可以看相关的 PDF 文档；

在没有使用 force index(a) 的时候，MySQL 用错了索引，导致执行时间更长；

### 优化器的逻辑

优化器选择索引的目的，就是找到一个最优的方案，并用最小的代价去执行；

数据库中，扫描行数是影响执行代价的因素之一；

扫描行数越少，意味着访问磁盘数据的次数越少，消耗的 CPU 资源越少；

**扫描行数如何判断？**

根据统计信息来估算记录数；

统计信息就是索引的“区分度”，值的数量，通过 show index 命令可以显示；

会发现索引的基数都不一样，因为这是估计出来的值；

**MySQL 如何得到索引的基数？**

采样统计的方法；

选择 N 个数据页，统计数据页上不同的值得到平均数，并且乘以页数；

数据表更新，当更新数超过 1/M，就会触发索引基数的重新计算；

索引统计只是一个方面，具体语句来说，优化器还要判断实际上会扫描多少行；

有偏差的话，优化器就会考虑其他方面的因素来进行索引选择，比如是否需要回表查询等；

**重新统计索引信息？**

使用 analyze table t 命令；

如果发现 explain 的结果和预估的 rows 相差过大，可以通过 analyze 重新组织索引；

### 索引选择异常和处理

遇到原本执行很快的语句，执行速度比预期的慢得多，该如何解决？

**方法一：**

通过 force index 来强制使用索引；

**方法二：**

修改语句，引导优化器选择我们想要使用的索引；

比如根据语句的功能来进行独特的操作；

或者根据数据特征进行初步的诱导，再进行后续的操作；

**方法三：**

新建更合适的索引，来提供给优化器做选择，或删掉误用的索引；

### 小结

对于索引统计信息不准确，可以使用 analyze table 来处理；

对于优化器误判的情况，可以使用 force index 来处理，或者通过修改语句进行引导；

#### 上期问题

主机重启是否会丢失 change buffer？

不会，因为 change buffer 是会被刷到磁盘中的，在 redo log 中会顺序写入；

merge 操作：

1. 从磁盘读入数据页；
2. 从 change buffer 中找到相应修改并应用到该页；
3. 写 redo log，包含数据变更和 change buffer 变更；



## 11｜怎么给字符串家索引

为字符串添加索引时，可以使用全部字符串建立索引，也可以使用前缀索引；

明显的，前缀索引可以减小占用空间；

前缀索引因为区分度的原因，可能会增加扫描行数，因为有些记录的前缀可能时一样的；

因此，使用前缀索引必须要定义好前缀长度，来尽可能使区分度（选择性）高；

区分度可以实现进行探查：

```sql
select count(distinct email) as L from SUser;
select
	count(distinct left(email,4)) as L4,
	count(distinct left(email,5)) as L5,
	count(distinct left(email,6)) as L6,
	count(distinct left(email,7)) as L7
from SUser;
```

前缀索引损失区分度，需要先定下一个可以接受的损失比例；

### 前缀索引对覆盖索引的影响

如果要使用覆盖索引的话，就无法使用前缀索引，因为索引节点的值不完全，需要进行回表查找；

使用前缀索引就没法使用覆盖索引进行优化了，这也是需要进行考虑的一件事；

### 其它方式

遇到前缀区分度不那么高的，比如说身份证号，前几位可能一个地方的人都一样，需要怎么建立索引呢？

如果能够确定只需要进行等值查询，没有范围查询的需要，可以：

* 使用倒序存储，之后每次查询的时候使用 reverse 函数；
* 使用 hash 字段，创建新的字段列保存校验码，比如使用 CRC32，避免冲突还需要进行全值判断；

两种方式的异同点：

1. 占用空间来看，hash 需要增加字段，不会在主键索引上消耗空间；
2. CPU 消耗方面，hash 需要每次进行 hash，而倒序存储需要每次进行 reverse，后者开销更小；
3. hash 查询效率稳定，因为冲突可能性小一些，而前缀索引可能会有很多相近的；

### 小结

字符串创建索引的场景：

* 直接创建完整的索引，比较消耗空间；
* 创建前缀索引，减少空间消耗，但会增加查询扫描次数，并且不能使用覆盖索引；
* 倒序存储，再创建前缀索引，用于正序前缀区分度较低的情况；
* hash 索引，创建新的 hash 列，有额外的存储和计算消耗；



## 12｜为什么 MySQL 会抖一下

一条 SQL 语句，在正常执行的时候很快，但有时会突然变得很慢，且这样的场景难以复现；

内存数据页是新且正确的，当内存数据页跟磁盘数据页内容不同的时候，称内存页为脏页；

内存数据写入到磁盘后，内存数据页跟磁盘数据页内容一样，就是干净页；

平时执行很快的操作，就是在写内存和日志，而很慢的时候可能就是在刷脏页；

**什么情况下会引发 flush？**

* redo log 满了，就需要停止所有更新，将 redo log 中的 checkpoint 往前推进；
* 系统内存不足，需要淘汰一些数据页给别的数据页使用，如果淘汰的是脏页就需要刷盘，保证状态简单；
	* 如果数据页在内存，那么内存中是正确的；
	* 如果数据不在内存，那么磁盘中是正确的；
* 系统空闲时；
* 系统关闭时；

**不同场景对性能的影响？**

后两种其实无关紧要；

第一种要尽量避免，会导致 MySQL 的响应能力（更新）变为 0；

第二种情况是常态；

InnoDB 管理内存，缓冲池中的内存页有三种状态：

* 没有使用的；
* 脏页；
* 干净页；

会将最久不使用的页面淘汰，此时如果是干净页，直接淘汰；

如果是脏页，要刷到磁盘才能进行淘汰；

可能影响性能：

* 一个查询要淘汰的脏页数太多，导致查询响应时间变长；
* 日志写满，更新全部堵住；

InnoDB 有用于控制脏页比例的机制；

### InnoDB 刷脏页的控制策略

首先，要明确告诉主机 IO 能力，innodb_io_capacity，设置成磁盘的 IOPS；

如果主机用的是 SSD，那么该值其实可以很大，通过 fio 工具来进行测试；

其次，要控制刷脏页的速度，考虑脏页比例和 redo log 的写盘速度；

innodb_max_dirty_pages_pct 是脏页比例上限，默认 75%；

另外，redo log 写盘速度也会经过一系列计算计算出来；

并进一步得到刷脏页的速率；

刷脏页的过程是需要额外的 IO 的；

平时要尽量不要让它轻易接近默认的上限；

脏页比例通过 innodb_buffer_pool_pages_dirty/innodb_buffer_pool_pages_total 得到的；

另外有一个有趣的策略：

Innodb 在刷脏页的过程中，如果旁边也有脏页的话，将其也刷进去，并不断传播；

这是为了使能够做到磁盘顺序 IO，效率会高，但很明显会影响正常的执行速率；

如果使用 SSD，innodb_flush_neighbors 设置为 0 即可；

### 小结

对于内存脏页的处理；

#### 上期问题

增加列来存储相应的字段并建立索引即可；



## 13｜为什么表数据删掉一半，表文件大小不变

聊聊数据表的空间回收；

InnoDB 表包含两部分，即表结构定义和数据；

在 8.0 版本以前，表结构存储在 .frm 为后缀的文件里；

在 8.0 版本以后，把表结构定义放在系统数据表内；

不过表结构定义的大小很小，一般指考虑表数据所占的空间；

### 参数 innodb_file_per_table

表数据既可以存在共享表空间里，也可以是单独的文件，行为由 innodb_file_per_table 控制；

该参数设置 OFF，表的数据放在系统共享表空间，跟数据字典放在一起；

该参数设置 ON，表数据存储在 .idb 文件中；

不论使用哪个版本，建议都将该值设置为 ON；

一个表单独存储为一个文件更容易管理，而且在不需要的时候，通过 drop table 可以回收空间；

如果是放在共享表空间，即使表删除了，空间也不会被回收；

#### innodb_file_per_table 优化

https://blog.csdn.net/JesseYoung/article/details/42236615

共享表空间：某一数据库所有表数据、索引文件全部放在同一文件中；

独立表空间：每一数据表都生成单独的文件来进行存储，包括 .frm 描述文件和 .idb 数据文件；

##### 优缺点

共享表空间的优点：可以将表空间分成多个文件存放到各个磁盘上，表空间大小不受表大小限制；

共享表空间的缺点：表和索引的混合存储，如果大量删除后，会存在大量空隙且无法回收；

独立表空间的优点：

1. 表有独立的表空间，独立存储数据和索引；
2. 可以实现单表在不同数据库中移动；
3. 删除数据后表空间的碎片可以通过不同方式进行回收；

独立表空间的缺点：单表过大；

### 数据删除流程

如果要删除 R4 的记录，InnoDB 只会把记录标记为删除，再在下次该位置要插入时复用；

磁盘文件的大小并不会缩小；

如果删掉了一整个数据页上的数据？那该页就可以复用了；

**数据页的复用和数据记录的复用是不同的**

记录的复用，只限于符合范围条件的；

数据页的复用，则是可以应用到 B+ 树的任何一个位置；

如果相邻两个数据页的利用率都很低，系统就会把两个数据页合并；

如果使用 delete 删除整个表？结果就是全部标记为已删除可复用，但文件大小不变；

**不止删除数据会造成空洞，插入数据也会**

如果数据按照索引顺序插入，那么数据页就是紧凑的；

如果数据随机插入，可能会造成索引数据页的分裂；

如果是更新索引上的值，可以理解为删除一个再插入一个，其实也会造成空洞的；

需要进行表的重建，来去掉空洞；

### 重建表

如果要对 A 做收缩，如何进行呢？

可能会考虑临时表 B，将 A 按索引顺序插入，完成后再用 B 替换 A 即可；

可以使用 `alter table A engine=InnoDB` 命令来重建表；

在 MySQL 5.5 之前，就是用临时表 B 来操作的；

但在该过程中，如果有数据写入到 A 表，可能就会丢失，因此更新 A 的操作需要被阻塞；

MySQL 5.6 开始，引入 Online DDL，对该操作进行了优化：

1. 建立临时文件，扫描表 A 主键的所有数据页；
2. 用数据页中表 A 的记录生成 B+ 树，存储到临时文件中；
3. 生成临时文件的过程中，将所有对 A 的操作记录在日志文件 row log 中；
4. 临时文件生成后，将日志文件的操作应用到临时文件中；
5. 用临时文件替换 A 的数据文件，其实临时文件也不一定是最紧凑的吧，因为日志的操作可能使他变化；

不过 DDL 不是要获取 MDL 写锁么，其实 alter 语句在拷贝数据时已经退化成了读锁，就不会锁住其他查询了；

为什么要退化？不阻塞其他增删改查操作；

为什么不干脆直接解锁？防止同时有其他的 DDL 干扰；

上述的重建方法其实比较消耗 IO 和 CPU，因此要小心地进行控制；

#### 元数据锁 MDL

##### 什么是 MDL 锁

MDL 维护表元数据的一致性，当有事务进行的时候，不允许对元数据进行写入操作；

MDL 解决了两个问题：

* 事务隔离问题，比如 A 前后两次查询，B 在其中更改了表结构，造成不可重复读；
* 数据复制问题，Slave 在重做时如果出现表结构更改比更新更前导致的错误；

MDL 是 Server 层的表级锁，每执行 DML 和 DDL 都会进行 MDL 的申请；

DML 锁需要 MDL 读锁，DDL 锁需要 MDL 写锁；

MDL 锁是系统自动的，无法干预，且读读共享、读写互斥、写写互斥；

申请 MDL 锁的操作会形成一个队列，队列中写锁获取优先于读锁；

一旦出现写锁等待，当前操作会阻塞，后续的所有操作都会被阻塞；

事务申请到 MDL 锁，提交之后才会进行锁的释放；

有个特殊情况，如果事务中包含 DDL 操作，那么会进行隐式的 commit，来保证 DDL 是单独的事务，同时保证元数据排他锁的释放；

##### 模拟与查找 MDL 锁

MySQL 5.7 中，perfomance schema 库中新增了 metadata locks 表，专门记录 MDL 的信息；

首先要开启 MDL 锁的记录：

```mysql
UPDATE performance_schema.setup_instruments
SET ENABLED = 'YES', TIMED = 'YES'
WHERE NAME = 'wait/lock/metadata/sql/mdl';
```

模拟和查找 MDL 的过程：

1. 开启事务 1 进行查询但不提交，获取 MDL 读锁；
2. 开启事务 2 进行更新，获取 MDL 写锁时阻塞；
3. 查询所有会话 `show processlist` 会发现 MDL 锁，`Waiting for table metadata lock`；
4. 查看 metadata_locks 表记录，以及联合其他表，能够进行冲突会话的定位，杀死即可；

##### 如何优化与避免 MDL 锁

避免 MDL 锁的发生：

* 开启 metadata_locks 表记录 MDL 锁；
* 设置参数 lock wait timeout 为较小值，使被阻塞端主动停止；
* 规范使用事务，避免长事务；
* 增强监控告警，及时发现MDL锁；
* DDL 在业务低谷做；
* 少用工具开启事务进行查询，图形化工具要及时关闭。

### Online 和 inplace

online 和 inplace 可能会概念混淆；

在 online DDL 中，tmp_file 临时文件是在 InnoDB 内创建的，不是 Server 层的临时文件；

对于 Server 来说，没有把数据移动到临时表，那么就是一个原地 inplace 操作；

但其实这个 inplace 是虚假的原地，对于 online DDL 来说；

onlien DDL 重建表的语句隐含的意思是：

```mysql
alter table t engine=innodb, ALGORITHM=inplace;
```

同 inplace 相反的就是 copy：

```mysql
alter table t engine=innodb, ALGORITHM=copy;
```

不过，inplace 和 online 不是同一个意思，比如给 InnoDB 表增加全文索引：

```mysql
alter table t add FULLTEXT(field_name);
```

这个过程是 inplace 的，不过会阻塞增删改查的操作；

online 和 inplace 的关系：

* DDL 如果是 Online 的，那就是 inplace 的；
* 反过来未必，如果 DDL 是 inplace 的，那也不一定是 Online 的；

**optimize table、analyze table、alter table 区别：**

* alter table 是默认的 online DDL，自 MySQL 5.6 开始；
* analyze table 只是重新组织统计信息，和表结构无关，加 MDL 读锁；
* optimize 是 alter 和 analyze 的合体；

### 小结

delete 不会改变文件大小，还需要进行 alter；

#### 上期问题

如果一个高配的机器， redo log 设置太小， 会发生什么情况；

间隔很短就要阻塞所有操作，去进行 checkpoint 的推进；

表现为磁盘压力很小， 但是数据库出现间歇性的性能下跌。



## 14｜count(*) 为什么这么慢，该如何做？

随着表的行数增加，count(*) 变得越来越慢，为什么？

### count(*) 的实现方式

在不同的 MySQL 引擎中，count(*) 有不同的实现方式；

* MyISAM 把表的总行数记录了，在计算时直接获取，没有条件的 count；
* InnoDB 需要一行一行地取出来再累积计数；

**为什么 InnoDB 不也存一个数字呢？**

即使是同一时刻的多个查询，由于多版本并发控制，InnoDB 应该返回多少行也是不确定的；

可重复读的默认隔离级别下，事务对于自己可见的行记录都是需要进行判断的；

需要一行一行取出来，才能依次进行判断；

InnoDB 是索引组织表，因此优化器会找到最小的那棵树来遍历；

**在保证逻辑正确的前提下，尽量减少扫描的数据量，是数据库系统设计的通用法则之一；**

show table status 的 table rows 是采样计算的，不能作为 count(*) 的结果；

小结：

* MyISAM count(*) 很快，但是不支持事务；
* show table status 结果很快，但是是不准确的；
* InnoDB count(*) 会遍历全表，结果正确但是有性能问题；

**如何来做呢？只能自己来进行计数；**

也就是说需要找一个地方，把操作记录表的行数记录下来；

### 缓存系统保存计数

缓存系统可能会丢失更新；

如果 Redis 在持久化之前宕机了，就意味当前的变化无法在重启之后恢复；

不过这个值重新读取数据库更新一次，是否就可以了呢？是的；

**实际上将计数保存在缓存中，不只是丢失更新的问题，即使 Redis 正常工作，值在逻辑上还是不精确的；**

缓存和数据库本身没有原子性，因此会存在不一致；

### 数据库内保存计数

**将该计数直接放到数据库里单独的一张计数表C中；**

解决了崩溃丢失的问题，InnoDB 支持崩溃恢复数据不丢失；

利用事务的特性来进行解决；

事务的可重复度隔离级别，就能够实现计数和查询记录的一致性；

### 不同的 count 用法

count(*)、count(主键id)、count(字段) 和 count(1) 等不同用法的性能；

count(*)、count(主键id)、count(1) 表示满足条件的结果集行数；

count(字段) 表示不为 NULL 的总个数；

在分析性能差异的时候，需要记住如下的原则：

* server 层要什么就给什么；
* InnoDB 只给必要的值；
* 优化器只优化了 count(*) 的语义为取行数，其他语句的优化并没有做；

对于 count(主键id)，会遍历整张表，将所有的 id 返回给 server，server 进行累计；

对于 count(1)，会遍历整张表，每行填 1 返回给 server，server 进行累计；

明显的，1 会比 id 快，因为不需要解析数据和拷贝；

对于 count(字段)：

* 如果是 not null，一行行读出记录，判断不能为 null，累计；
* 如果允许 null，执行时判断可能是 null，还是要把值取出来再判断一下，不是 null 才累计；

count(*) 是例外，专门进行优化，不会取值；

因此，**按照效率排列 count(\*)>count(1)>count(id)>count(字段)**；

### 小结

计数放在不同于 MySQL 的系统中，是无法保证一致性的；

计数同样放在 MySQL 中，可以通过事务本身的特性来保证计数的正确性；

#### 上期问题

**什么时候 alter table t engine=innodb 占用的表空间会变大？**

在 DDL 期间，有 DML 执行，那么就会引入一些新的空洞；

另外，在重建表的时候，InnoDB 不会把整张表占满，而是会有 1/16 页的预留空间，其实重建并不是最紧凑的；



## 15｜答疑文章（一）：日志和索引相关问题

### 日志相关问题

#### 在两阶段提交的不同阶段，MySQL 发生异常重启，是如何保证数据完整性的？

按照不同的时间阶段来分：

1. 写入 redo log 处于 prepare 阶段；
2. 时刻 A；
3. 写入 binlog；
4. 时刻 B；
5. 提交事务，处于 commit 状态；

**commit 的概念：**

* MySQL 语法中，和 begin/start transcation 对应的 commit；
* 事务提交过程的小步骤，commit 后事务就提交完成了；
* commit 语句包含 commit 步骤；

**在两阶段的不同时刻，MySQL 异常重启会出现什么样的现象；**

1. 时刻 A 发生崩溃，binlog 还没写，redo log 也没提交，崩溃恢复不需要恢复什么数据；
2. 时刻 B 发生崩溃，如果 binlog 是完整的，那么查看 redo log 的 prepare 部分并提交；

**MySQL 如何知道 binlog 是完整的；**

事务的 binlog 是有完整格式的；

* statement 格式的 binlog，最后会有 commit；
* row 格式的 binlog，最后会有 xid event；

另外，5.6.2 之后，引入了 binlog-checksum 参数，验证 binlog 的正确性；

**redo log 和 binlog 是如何关联起来的；**

有共同的数据字段，叫 xid；

崩溃恢复的时候，会按顺序扫描 redo log：

* 如果碰到既有 prepare 又有 commit 的 redo log，就直接提交；
* 如果碰到只有 prepare 没有 commit 的 redo log，就拿着 xid 去 binlog 找对应的事务；

**处于 prepare 的 redo log 加上完整的 binlog，重启就能恢复，会什么要如此设计；**

数据与备份的一致性；

在时刻 B，binlog 写入之后，就会被从数据库拿出来使用，所以主库也要进行提交保证主从的一致性；

**为什么还需要两阶段提交呢，不直接 redo log 写完，再写 binlog，崩溃恢复的时候看两个日志是否都完整；**

两阶段提交是经典的分布式系统问题，并不是 MySQL 独有的；

如此做的必要性，事务的持久性问题；

如果 redo log 写入，binlog 失败，但是 redo log 又不能回滚，整个数据和 binlog 就不一致了；

两阶段提交是为了保证各方都能够有机会表示 ok 再完全提交；

**只用 binlog 来支持可行吗；**

不可以，同一事务...看不太懂...

**只用 redo log 来支持可行吗；**

能够实现崩溃恢复的功能；

但 binlog 拥有 redo log 无法实现的功能：

* 归档，redo log 循环写，无法实现归档的功能；
* MySQL 的高可用基础就是 binlog 日志；
* 另外不少下游系统、异构数据库都是通过消费 binlog 来进行的；

**redo log 一般设置多大；**

太小会导致快速写满并强制刷盘，WAL 机制的能力就无法发挥了；

设置为 4 个文件，每个 1 GB；

**数据写入最终落盘，是从 redo log 更新还是 buffer pool 进行更新；**

redo log 并没有记录完整的数据页，更新肯定不是从 redo log 过去的，而是从内存中的数据页过去的；

正常运行，内存中的数据也被修改同磁盘中的不同，是为脏页，最终数据落盘就是把内存数据刷到磁盘上；

崩溃恢复场景，判断数据也可能丢失数据，就先将磁盘数据读到内存，再应用 redo log，再刷到磁盘上；

**redo log buffer 是什么，是先修改内存还是先写 redo log；**

事务更新过程中，日志要写多次，但是没有提交的事务不能够写到 redo log 中，就需要先写到 buffer 内；

真正把日志写到 redo log 是在事务 commit 的时候；

### 业务设计问题

业务有需求，A、B 互相关注则成为好友；

设计两张表，like 和 friend，like 有 user_id、liker_id 字段，设置符合唯一索引 uk_user_id_liker_id；

A 关注 B 时，先查询对方是否关注自己，有则成为朋友，没有则单向关注；

在 A、B 同时关注对方的时候，会出现无法成为好友的情况，该如何处理；

解决方法可以是**修改表的设计**；

比如说同一对关系只是用一条记录，并且通过另一个字段来表示两者之间相关的关注关系；

同时保证 user_id < like_id，使得记录只有一条；

在执行的时候 insert ... on duplicate 占住行锁；

### 上期问题

用计数表记录业务表的总行数，在插入数据的时候需要给计数值加 1；

逻辑实现是启动一个事务，执行两个语句：

1. insert into 数据表；
2. update 计数表，计数值加 1；

从系统并发的角度考虑如何安排这两个语句的顺序；

将 update 放在后面，因为如果有多个业务逻辑 insert 同一个业务表，会出现锁的竞争吧；



## 16｜order by 是如何工作的？

根据字段排序显示结果的需求；

以以下 sql 为例来解释如何执行：

```mysql
select city, name, age from t where city='杭州' order by name limit 1000;
```

### 全字段排序

通过 explain 查看执行计划，Extra 中 Using filesort 就是需要进行文件排序；

MySQL 会给每个线程分配一块内存用于排序，即 sort_buffer；

具体步骤如下：

1. 初始化 sort_buffer，确定需要存放 city、name、age 字段；
2. 从索引 city 找到第一个满足的；
3. 回到主键索引取出整行数据中的 city、name、age 字段，并放入 sort_buffer 中；
4. 从索引 city 取出下一个 id；
5. 重复直到 city 的值不满足查询条件为止；
6. 对 sort_buffer 中的数据按照字段 name 进行快速排序；
7. 取出 1000 个返回给客户端；

该过程称为全字段排序，也就是说对于全部的 city='杭州' 都进行了读取和排序；

按照 name 排序，如果内存够大只需要内部排序，否则还可能需要使用外部排序；

#### 判断是否使用临时文件的方法

```mysql
/* 打开 optimizer_trace 只对本线程有效 */
set optimizer_trace='enable=on';

/* @a 保存 Innodb_rows_read 的值 */
select VARIABLE_VALUE into @a from performance_schema.session_status where variable_name='Innodb_rows_read';

/* 执行语句 */
select city, name, age from t where city='杭州' order by name limit 1000;

/* 查看 oprimizer_trace 的输出 */
SELECT * FROM `information_schema`.`OPTIMIZER_TRACE`;

/* @b 保存 Innodb_rows_read 的值 */
select VARIABLE_VALUE into @b from performance_schema.session_status where variable_name='Innodb_rows_read';

/* 计算 Innodb_rows_read 的前后差值 */
select @b-@a;
```

该方法通过查看 optimizer_trace 的结果来确认的；

<img src="/Users/xus7/Library/Application Support/typora-user-images/image-20211019200437795.png" alt="image-20211019200437795" style="zoom:50%;" />

可以从 number_of_tmp_files 查看使用临时文件的数量；

如果 sort_buffer_size 超过排序需要的空间，那么 number_of_tmp_files 就为 0；

rows 表示查询到了 4000 行数据，examined_rows 表示排序了 4000 行数据；

sort_mode 中 packed_additional_fields 说明做了紧凑处理，即 name 字段根据字符数紧凑；

select @b-@a 说的是整个过程扫描了 4000 行数据，不过如果从表中取数据时，也会 +1；

### rowid 排序

在 sort_buffer 中如果字段太多，可能会导致存储的数据很少，需要分成很多临时文件；

**如果 MySQL 认为排序时单行长度过大会如何做呢？**





